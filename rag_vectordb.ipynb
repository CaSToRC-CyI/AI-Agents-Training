{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1284,
     "status": "ok",
     "timestamp": 1753085220573,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "uScNqZuCj7Bz",
    "outputId": "56f04e8e-c4e7-4b9e-9c43-a24aef1a4410"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/CaSToRC-CyI/AI-Agents-Training.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1753085220591,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "4N5gGzBikAi_",
    "outputId": "f5e05a46-ce3e-4589-ef1e-b3fd1d9158df"
   },
   "outputs": [],
   "source": [
    "%cd ./AI-Agents-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 617,
     "status": "ok",
     "timestamp": 1753085221213,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "a2Rdjph0iaaJ",
    "outputId": "d8bffd44-711f-40aa-c42b-226b3fb3c0a3"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "uv pip install haystack-ai\n",
    "uv pip install milvus_haystack\n",
    "uv pip install pymilvus\n",
    "uv pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8772,
     "status": "ok",
     "timestamp": 1753085229994,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "-jUgcLW0idZq"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from getpass import getpass\n",
    "from haystack import Pipeline\n",
    "from haystack.components.converters import DOCXToDocument\n",
    "from haystack.components.preprocessors import DocumentCleaner\n",
    "from haystack.components.preprocessors import DocumentSplitter\n",
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "\n",
    "from milvus_haystack import MilvusDocumentStore\n",
    "from milvus_haystack.milvus_embedding_retriever import MilvusEmbeddingRetriever\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.dataclasses import ChatMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23350,
     "status": "ok",
     "timestamp": 1753085253365,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "H7Uy9jYxtj8l",
    "outputId": "f9e9c3db-06f8-42cd-80e4-496b84579f5d"
   },
   "outputs": [],
   "source": [
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1753085253377,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "t5YtLuUStmfq"
   },
   "outputs": [],
   "source": [
    "DOCUMENTS_DIR = Path(\"./dummy_data/documents_dir\")\n",
    "FILES = [file.resolve() for file in DOCUMENTS_DIR.rglob(\"*\") if file.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1753085253999,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "QY-6fN4BuY3B",
    "outputId": "e9921fb8-86b1-4cce-b51f-e1cf7e0b1d3e"
   },
   "outputs": [],
   "source": [
    "converter = DOCXToDocument()\n",
    "\n",
    "result = converter.run(sources=FILES)\n",
    "print(f'{result[\"documents\"][0].meta[\"file_path\"]}')\n",
    "print(result[\"documents\"][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1753085295192,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "0AuTkCodBINC"
   },
   "outputs": [],
   "source": [
    "connection_args={\"uri\": \"./rag_vectordb.db\"}\n",
    "document_store = MilvusDocumentStore(\n",
    "    connection_args=connection_args,\n",
    "    drop_old=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9592,
     "status": "ok",
     "timestamp": 1753085421825,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "8-VBtjAbBIvU",
    "outputId": "36a1e3b6-8c04-4cde-fa7a-19d6e175316a"
   },
   "outputs": [],
   "source": [
    "indexing_pipeline = Pipeline()\n",
    "indexing_pipeline.add_component(\"converter\", DOCXToDocument())\n",
    "indexing_pipeline.add_component(\"cleaner\", DocumentCleaner())\n",
    "indexing_pipeline.add_component(\"splitter\", DocumentSplitter(split_by=\"sentence\", split_length=2))\n",
    "indexing_pipeline.add_component(\"embedder\", OpenAIDocumentEmbedder())\n",
    "indexing_pipeline.add_component(\"writer\", DocumentWriter(document_store))\n",
    "indexing_pipeline.connect(\"converter\", \"cleaner\")\n",
    "indexing_pipeline.connect(\"cleaner\", \"splitter\")\n",
    "indexing_pipeline.connect(\"splitter\", \"embedder\")\n",
    "indexing_pipeline.connect(\"embedder\", \"writer\")\n",
    "indexing_pipeline.run({\"converter\": {\"sources\": FILES}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 301,
     "status": "ok",
     "timestamp": 1753085451437,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "__9Yvu72CIJj",
    "outputId": "75aa0da6-585e-46d8-cae0-6f28902bfdf5"
   },
   "outputs": [],
   "source": [
    "question = \"Tell me a bit about QuantumStream\"  # You can replace it with your own question.\n",
    "\n",
    "retrieval_pipeline = Pipeline()\n",
    "retrieval_pipeline.add_component(\"embedder\", OpenAITextEmbedder())\n",
    "retrieval_pipeline.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "retrieval_pipeline.connect(\"embedder\", \"retriever\")\n",
    "\n",
    "retrieval_results = retrieval_pipeline.run({\"embedder\": {\"text\": question}})\n",
    "\n",
    "for doc in retrieval_results[\"retriever\"][\"documents\"]:\n",
    "    print(doc.content)\n",
    "    print(\"-\" * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1753085473942,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "St-aK-SvCRKM",
    "outputId": "989cb78d-9959-4c41-b621-a9f78cb53a84"
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Answer the following query based on the provided context. If the context does\n",
    "                     not include an answer, reply with 'I don't know'.\\n\n",
    "                     Query: {{query}}\n",
    "                     Documents:\n",
    "                     {% for doc in documents %}\n",
    "                        {{ doc.content }}\n",
    "                     {% endfor %}\n",
    "                     Answer:\n",
    "                  \"\"\"\n",
    "\n",
    "llm = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "\n",
    "rag_pipeline = Pipeline()\n",
    "rag_pipeline.add_component(\"text_embedder\", OpenAITextEmbedder())\n",
    "rag_pipeline.add_component(\"retriever\", MilvusEmbeddingRetriever(document_store=document_store, top_k=3))\n",
    "rag_pipeline.add_component(\"prompt_builder\", ChatPromptBuilder(template=[ChatMessage.from_user(prompt_template)]))\n",
    "\n",
    "rag_pipeline.add_component(\"llm\", llm)\n",
    "rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "rag_pipeline.connect(\"retriever\", \"prompt_builder\")\n",
    "rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")\n",
    "\n",
    "messages = [ChatMessage.from_user(prompt_template)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2602,
     "status": "ok",
     "timestamp": 1753085478947,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "4oP0KKoxCXFP",
    "outputId": "6214fe71-a4f6-42e3-8cad-a5d6849bf674"
   },
   "outputs": [],
   "source": [
    "results = rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"query\": question}})\n",
    "\n",
    "print('RAG answer:\\n\\n', results[\"llm\"][\"replies\"][0].text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOgnacqgWL73uCmRWgaPl7T",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
