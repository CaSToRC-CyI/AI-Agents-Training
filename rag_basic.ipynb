{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a basic RAG pipeline with Haystack\n",
    "\n",
    "Retrieval Augmented Generation (RAG) is a method that combines information retrieval with generative models to provide accurate and context-aware respones.\n",
    "\n",
    "It is particularly useful for tasks requiring domain-specific knowledge or large-scale document retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section clones the relevant data we are going to use in this notebook, while also installed all the relevant packages.\n",
    "\n",
    "\n",
    "**NOTE: Make sure to change the notebook runtime to T4 GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1481,
     "status": "ok",
     "timestamp": 1753079702369,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "PwuT0l91UMj5",
    "outputId": "f72d41b6-42b3-4cc5-ade7-2a0383db9aaf"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/CaSToRC-CyI/AI-Agents-Training.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1753079702373,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "pHBMCIH7S4-s",
    "outputId": "46dc2166-8481-44c4-87ee-f1dda7e41191"
   },
   "outputs": [],
   "source": [
    "%cd ./AI-Agents-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 882,
     "status": "ok",
     "timestamp": 1753079703254,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "lApOubh5mHFt",
    "outputId": "4480b1ac-9dee-4af2-8a81-45bc6a98f3b1"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "uv pip install haystack-ai\n",
    "uv pip install datasets -U\n",
    "uv pip install \"sentence-transformers>=4.1.0\"\n",
    "uv pip install huggingface_hub -U\n",
    "uv pip install python-docx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 38536,
     "status": "ok",
     "timestamp": 1753079741794,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "hHOwsEtUNG8h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack import Document\n",
    "from haystack.components.embedders import OpenAIDocumentEmbedder, OpenAITextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.dataclasses import ChatMessage\n",
    "from haystack.components.builders import ChatPromptBuilder\n",
    "from haystack.components.generators.chat import OpenAIChatGenerator\n",
    "from haystack.components.converters import DOCXToDocument\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Open-AI API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69185,
     "status": "ok",
     "timestamp": 1753079810991,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "ZGwCrrTCNIwT",
    "outputId": "53c380c8-53c6-45ac-eeb0-135c2606e330"
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter OpenAI API key:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data to Haystack Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haystack uses these abstraction called *Documents*. They can hold text, tables, and binary data.\n",
    "\n",
    "They have the following unique features:\n",
    "\n",
    "- Unique ID for each document.\n",
    "- Multiple content types are supported.\n",
    "- Custom metadata and scoring for advanced document management.\n",
    "- Optional embeddings for AI-based applications\n",
    "\n",
    "**Example:**\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Document(metaclass=_BackwardCompatible):\n",
    "    id: str = field(default=\"\")\n",
    "    content: Optional[str] = field(default=None)\n",
    "    blob: Optional[ByteStream] = field(default=None)\n",
    "    meta: Dict[str, Any] = field(default_factory=dict)\n",
    "    score: Optional[float] = field(default=None)\n",
    "    embedding: Optional[List[float]] = field(default=None)\n",
    "    sparse_embedding: Optional[SparseEmbedding] = field(default=None)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert our files do Haystack Documents, we need to use a *converter*. In our case, since we only have .docx documents, we can go ahead and use Haystack's DOCXToDocument converter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCUMENTS_DIR = Path(\"./dummy_data/documents_dir\")\n",
    "FILES = [file.resolve() for file in DOCUMENTS_DIR.rglob(\"*\") if file.is_file()]\n",
    "converter = DOCXToDocument()\n",
    "\n",
    "docs = []\n",
    "for file in FILES:\n",
    "    result = converter.run(sources=[file])\n",
    "    docs.extend(result[\"documents\"])  # Append the converted documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect a sample document from our database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1753079812655,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "mcWeRIgwNMWS",
    "outputId": "8d4e89e6-710e-454e-c954-5751d3956ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üõ†Ô∏è Annual Company Hackathon 2025 ‚Äì Full Event Brief\n",
      "üìÖ Dates: July 15‚Äì17, 2025\n",
      "üìç Location: Hybrid (Company HQ & Remote Access)\n",
      "‚è∞ Duration: 48 Hours\n",
      "üéØ Theme: \"Innovate with Impact: Building the Future with Internal APIs\"\n",
      "\n",
      "üß† Event Overview\n",
      "The Annual Company Hackathon is a flagship innovation event designed to bring together employees from across departments to collaborate, experiment, and build transformative solutions. This year‚Äôs hackathon will run from Tuesday, July 15 at 10:00 AM to Thursday, July 17 at 12:00 PM, offering a 48-hour window for teams to ideate, prototype, and present their projects.\n",
      "The 2025 theme, \"Innovate with Impact\", emphasizes the use of our internal APIs to create tools, applications, or enhancements that can drive real value‚Äîwhether for internal operations, customer experience, or future product lines.\n",
      "\n",
      "üë• Eligibility & Team Formation\n",
      "Open to all employees, including full-time, part-time, interns, and contractors.\n",
      "Teams can consist of 1 to 5 members.\n",
      "Cross-functional collaboration is encouraged‚Äîengineers, designers, analysts, marketers, and operations staff are all welcome.\n",
      "A Team Formation Mixer will be held virtually on July 10 at 4:00 PM to help individuals find teammates.\n",
      "Participants can register solo and request to be matched with a team via the Hackathon Portal.\n",
      "\n",
      "üß∞ Available Resources\n",
      "Participants will be provided with:\n",
      "Internal API Access:\n",
      "\fUser Profile API\n",
      "Analytics & Metrics API\n",
      "Notification & Messaging API\n",
      "Permissions & Access Control API\n",
      "Product Catalog API\n",
      "Hackathon Dev Environment:\n",
      "Pre-configured cloud workspaces\n",
      "Sample datasets\n",
      "API documentation and SDKs\n",
      "Support Channels:\n",
      "Dedicated Slack workspace (#hackathon-2025)\n",
      "Live Q&A sessions with API owners\n",
      "1:1 mentorship slots with senior engineers and product managers\n",
      "\n",
      "üèÜ Prize Categories & Awards\n",
      "A total prize pool of $15,000 will be distributed across the following categories:\n",
      "üèÖ Most Innovative Solution ‚Äì \\$5,000\n",
      "Awarded to the team that demonstrates the most original and forward-thinking idea.\n",
      "üîß Best Use of Internal APIs ‚Äì \\$3,000\n",
      "Recognizes the most effective and creative integration of our internal APIs.\n",
      "üìà Highest Business Impact ‚Äì \\$3,000\n",
      "For the project with the greatest potential to improve internal workflows or customer outcomes.\n",
      "üé§ Best Demo & Presentation ‚Äì \\$2,000\n",
      "Honors the team with the most compelling and well-delivered demo.\n",
      "üó≥Ô∏è People‚Äôs Choice Award ‚Äì \\$2,000\n",
      "Voted on by all employees during the final showcase.\n",
      "\fAll winners will receive:\n",
      "Digital certificates\n",
      "Company-wide recognition\n",
      "A feature in the internal newsletter and intranet\n",
      "Optional fast-track to productization via the Innovation Incubator Program\n",
      "\n",
      "üßë‚Äç‚öñÔ∏è Judging Panel & Criteria\n",
      "The judging panel will consist of senior leaders from Engineering, Product, Design, and Strategy. Projects will be evaluated based on:\n",
      "Creativity & Originality (25%)\n",
      "Technical Execution (25%)\n",
      "Impact & Feasibility (25%)\n",
      "Presentation & Storytelling (25%)\n",
      "Bonus points may be awarded for:\n",
      "Cross-departmental collaboration\n",
      "Accessibility and inclusivity features\n",
      "Sustainability or ethical considerations\n",
      "\n",
      "üìÖ Event Schedule\n",
      "Date,Time,Activity\n",
      "July 10,4:00 PM,Team Formation Mixer (Virtual)\n",
      "July 15,10:00 AM,Kickoff Ceremony & API Briefing\n",
      "July 15,12:00 PM,Hacking Begins\n",
      "July 16,3:00 PM,Midpoint Check-In & Mentor Feedback\n",
      "July 17,12:00 PM,Submission Deadline\n",
      "July 17,2:00 PM,Demo Showcase (Live & Streamed)\n",
      "July 17,4:00 PM,Awards Ceremony & Closing Remarks\n",
      "\n",
      "üì¢ Registration Details\n",
      "Registration is open from June 15 to July 10.\n",
      "Sign up via the Hackathon Portal.\n",
      "Teams must submit:\n",
      "A working prototype or demo\n",
      "A 3-minute video presentation\n",
      "A short write-up (max 500 words) describing the problem, solution, and impact\n",
      "\n",
      "üí¨ Communication & Support\n",
      "Join the #hackathon-2025 Slack channel for announcements, team matching, and support.\n",
      "Live support will be available 24/7 during the event via Slack and Zoom.\n",
      "Mentors will host office hours on July 15 and 16 from 2:00‚Äì4:00 PM.\n",
      "\n",
      "üí° Inspiration from Past Hackathons\n",
      "2024 Winner: PulseCheck ‚Äì A real-time employee sentiment dashboard using the Analytics API, now in pilot with HR.\n",
      "2023 Winner: AutoRoute ‚Äì A smart ticket routing system for customer support, now integrated into our Helpdesk platform.\n",
      "2022 Winner: EcoTrack ‚Äì A sustainability tracker for internal operations, now part of our ESG reporting tools.\n",
      "\n",
      "\füß≠ FAQs\n",
      "Q: Can I work on an idea I‚Äôve already started?\n",
      "A: No. All work must be started and completed within the 48-hour window.\n",
      "Q: Can I use third-party APIs or tools?\n",
      "A: Yes, as long as the core functionality leverages our internal APIs.\n",
      "Q: What if I don‚Äôt finish my project?\n",
      "A: Submit what you have! Progress and potential are also considered in judging.\n",
      "Q: Will projects be considered for production?\n",
      "A: Yes. Winning and high-potential projects may be fast-tracked for further development.\n",
      "\n",
      "Let‚Äôs build something amazing together. See you at the hackathon!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': 'Cybersecurity Awareness Month.docx', 'docx': {'author': 'python-docx', 'category': '', 'comments': 'generated by python-docx', 'content_status': '', 'created': '2013-12-23T23:15:00+00:00', 'identifier': '', 'keywords': '', 'language': '', 'last_modified_by': 'Marios Constantinou', 'last_printed': None, 'modified': '2025-07-15T09:53:00+00:00', 'revision': 2, 'subject': '', 'title': '', 'version': ''}}\n"
     ]
    }
   ],
   "source": [
    "print(doc.meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Documents and performing RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Indexing components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to use our documents we need to perform 2 things:\n",
    "\n",
    "1. Turn them into embeddings with an *embedder*.\n",
    "2. Store them in a Haystack *Document Store* so they can be accessed later on.\n",
    "\n",
    "For our simple use-case, we will use an OpenAI document embedder to extract embeddings, and then we will store them in an *InMemoryDocumentStore*. Basically we are storing them in our system's RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753079812662,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "1AlEcKmCpKGw"
   },
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "doc_embedder = OpenAIDocumentEmbedder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings and store to Document Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go ahead and run the cell below to begin calculating the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3197,
     "status": "ok",
     "timestamp": 1753079816038,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "6PzhXdYlNPMf",
    "outputId": "7c35e281-c1a3-48e2-fb9e-b74885c5f492"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating embeddings: 1it [00:02,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 13 documents with embeddings in the document store.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n",
    "print(f\"Stored {len(docs_with_embeddings['documents'])} documents with embeddings in the document store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template for user\n",
    "\n",
    "This prompt template will be used by our LLM to generate a response based on our Query.\n",
    "\n",
    "Specifically, the LLM will read this text from top to bottom:\n",
    "\n",
    "- It will read the task, which is to respond to the user's query using the **provided context**.\n",
    "- It will then read some **General Guidelines**.\n",
    "- Then it will read the **provided context**.\n",
    "- And finally it will read the **user's query**.\n",
    "\n",
    "You can see that we pass the **context** and **user's query** through this template. This is why we use a prompt builder later on. This component constructs prompts dynamically by processing chat messages.\n",
    "\n",
    "Specifically, the *ChatPromptBuilder* component creates prompts using static or dynamic templates written in Jinja2 syntax, by processing a list of chat messages. The templates contain placeholders like {{ variable }} that are filled with values provided during runtime. You can use it for static prompts set at initialization or change the templates and variables dynamically while running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1753079816059,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "zXe8Du2HNQaM",
    "outputId": "2a431c63-2ca5-4cc0-bc98-42db16c803ed"
   },
   "outputs": [],
   "source": [
    "template = [\n",
    "    ChatMessage.from_user(\n",
    "        \"\"\"\n",
    "Respond to the User Query using the provided Context.\n",
    "\n",
    "General Guidelines:\n",
    "    - Ensure citations are concise and directly related to the information provided.\n",
    "    - If the answer is not found in the context, state this clearly instead of making assumptions.\n",
    "    - If the answer comes from several sources, make sure to cite every one of them, including their Source Filename, Source Chapter and Source Page.\n",
    "    - If information is region-specific, clarify which region it pertains to.\n",
    "    - Respond in the same language as the user‚Äôs query.  \n",
    "    - Do not use emojis.\n",
    "    - Be professional and punctual\n",
    "    - *Avoid* writing a conclusion or a follow-up at the end of each response unless you were asked to.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RAG Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the actual RAG pipeline we have the following components:\n",
    "\n",
    "- The *text_embedder* which takes the user's query and turns it into embeddings\n",
    "- The *retriever* which retrieves the relevant documents\n",
    "- The *chat_generator* which is our LLM\n",
    "- The *promot_builder* which was explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1753079816329,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "lQDnTWp6NSGQ"
   },
   "outputs": [],
   "source": [
    "text_embedder = OpenAITextEmbedder()\n",
    "retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "chat_generator = OpenAIChatGenerator(model=\"gpt-4o-mini\")\n",
    "prompt_builder = ChatPromptBuilder(template=template)\n",
    "\n",
    "# Initialize RAG pipeline\n",
    "basic_rag_pipeline = Pipeline()\n",
    "\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriever)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", chat_generator)\n",
    "\n",
    "# Connect the input/output of each component\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever.documents\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder.prompt\", \"llm.messages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We connect each component by defining the inputs and outputs.\n",
    "\n",
    "For example:\n",
    "\n",
    "- The *text_embedder* will take the user's query as an input and output *embeddings*. These embeddings will be the input of the *retriever*. The *retriever* will take that input as *query_embedding* and output a list of *documents* that are similar to that query.\n",
    "- Then, the *retriever* outputs the documents we mentioned, and pass them into our *prompt_builder*.\n",
    "- Finally, the *prompt_builder* will output the prompt and send it as an input to the *llm*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform RAG on our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to change the question to something else.\n",
    "\n",
    "Our documents contain information about the following topics:\n",
    "\n",
    "- Annual Hackathon the company is organizing\n",
    "- Cybersecurity Awareness Month\n",
    "- Employee Recognition Program\n",
    "- New Office Layout Plan\n",
    "- Office layout redesign plan\n",
    "- Product X Launch Timeline\n",
    "- Product Y Launch Timeline\n",
    "- QuantumStream product CLI Usage\n",
    "- QuantumStream product Data Encryption feature\n",
    "- QuantumStream product Plugin System\n",
    "- QuantumStream product REST API documentation\n",
    "- QuantumStream product Scheduler feature\n",
    "- QuantumStream product Scheduling tasks\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to ask anything relating to these topics.\n",
    "\n",
    "**Suggested prompts:**\n",
    "\n",
    "- \"Whats the purpose of the new office layout? Are we loosing our desks??\"\n",
    "- \"I am a new employee at the company. Onboard me about the QuantumStream product.\"\n",
    "- \"I cannot find the relevant email about the Hackathon, can you tell me more details about it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3779,
     "status": "ok",
     "timestamp": 1753079820154,
     "user": {
      "displayName": "Marios Constantinou",
      "userId": "08118670076332792273"
     },
     "user_tz": -180
    },
    "id": "szzh7B5INUUs",
    "outputId": "06cb9d3c-1329-4cb2-ee74-833689bf97f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the team! QuantumStream is an innovative platform designed for managing streaming data pipelines efficiently.\n",
      "  Below is an overview of its key components and functionalities to help you get up to speed:\n",
      "\n",
      "### QuantumStream CLI (Command-Line Interface)\n",
      "- **Purpose**: Facilitates command-line control for stream management, configuration, and diagnostics.\n",
      "- **Installation**: You can install the CLI using `pip install quantumstream-cli` or download it from the QuantumStream\n",
      "  Developer Portal.\n",
      "- **Core Commands**:\n",
      "  - `qs init`: Initialize a new QuantumStream project.\n",
      "  - `qs deploy`: Deploy your stream to a configured environment.\n",
      "  - `qs monitor`: Launches a real-time metrics dashboard.\n",
      "  - `qs diag`: Runs a diagnostics scan and outputs a health report.\n",
      "\n",
      "### QuantumStream REST API\n",
      "- **Purpose**: Enables integration with external applications for automation and monitoring.\n",
      "- **Authentication**: API key authentication via HTTP headers.\n",
      "- **Available Endpoints**: Includes `/stream/start`, `/metrics`, `/logs`, and more to manage your streaming pipeline\n",
      "  programmatically.\n",
      "\n",
      "### QuantumStream Scheduler\n",
      "- **Purpose**: Automates recurring tasks such as data ingestion, model retraining, and stream management.\n",
      "- **Configuration**: Tasks are defined using cron syntax in a centralized configuration file (`scheduler.yaml`).\n",
      "- **Supported Task Types**: Includes starting/stopping streams and ingesting data from external sources.\n",
      "\n",
      "### Data Encryption\n",
      "- **Security**: Supports AES-256 encryption for protecting sensitive data in transit and at rest.\n",
      "- **Configuration**: Encryption can be enabled at the project level within your `qs.config.yaml` file.\n",
      "\n",
      "### Plugin System\n",
      "- **Overview**: Extends QuantumStream's capabilities with modular plugins for custom data processing, connectors, and\n",
      "  validations.\n",
      "- **Development**: Plugins require implementation of the `IQuantumPlugin` interface and can be registered via the\n",
      "  `qs.config.yaml` file.\n",
      "\n",
      "### Monitoring & Diagnostics\n",
      "- **Real-Time Metrics**: Use the CLI to monitor throughput, latency, and resource usage.\n",
      "- **Diagnostics**: Run health checks to identify issues within the streaming setup.\n",
      "\n",
      "### Additional Resources\n",
      "- For more detailed usage and guides, visit the [QuantumStream CLI Documentation](https://example.com).\n",
      "- Engage with your team to learn best practices and any company-specific configurations or workflows.\n",
      "\n",
      "Feel free to reach out if you have any questions or need assistance as you begin working with QuantumStream!\n"
     ]
    }
   ],
   "source": [
    "question = \"I am a new employee at the company. Onboard me about the QuantumStream product.\" # Feel free to change this question\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "formatted_text = response[\"llm\"][\"replies\"][0].text\n",
    "wrapped_text = \"\\n\".join(\n",
    "    textwrap.fill(line, width=120, subsequent_indent=\"  \") if line.strip() else line\n",
    "    for line in formatted_text.splitlines()\n",
    ")\n",
    "\n",
    "print(wrapped_text)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyON7iiLmrYaPfbHl4IbRyS6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
